# Default values for nublado.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# Variables you absolutely need (with examples commented out):
#fqdn: 'example.com'
scheme: 'https://'

# Set up debugging, set to enable
debug: 'true'

vault_secrets:
  # Use the vault-secrets-operator to load secrets from vault
  # instead of creating them from values here.
  enabled: False

  # Path to load secrets for in the vault.
  path: ""

hub:
  uid: 768
  gid: 768
  #proxy_auth_token: ''
  #crypto_key: ''
  image: 'lsstsqre/sciplat-hub:latest'
  persistent_home: True

# Dask settings
dask:
  allow_spawn: 'true'
  restrict_nodes: ''
  max_workers: 25

lab:
  no_sudo: ''
  restrict_nodes: ''

  # If you don't want to use the prepuller to scan for images, put in a full
  # image here.
  # image_name: 'lsstsqre/sciplat-lab:latest'
  image_name: ''

  # Configure the scanner to find images to put in the spawner
  image:
    repo_host: ''
    repo_owner: 'lsstsqre'
    repo_name: 'sciplat-lab'
    cachefile: '/tmp/repo-cache.json'

    # Number of images of each type to put in the spawner page
    experimentals: 0
    dailies: 3
    weeklies: 2
    releases: 1

  resources:
    # Jupyterlab needs more than the default NodeJS stack size if many
    #  extensions are installed.
    nodejs_max_mem: '6144'
    # This is a comma-separated string to be used in an environment variable
    options_form_sizes: 'tiny,small,medium,large'
    # This is a zero-based index, so in the default list, 'small' is the
    #  default size
    size_index: 1
    # Each size has twice the capacity of the one below it.
    # This is the max CPU of the smallest size
    tiny_cpu_max: '0.5'
    # Generally 2048 for public cloud and 3072 at NCSA
    mb_per_cpu: 2048
    # For CPU and mem, (1 / size_range) is the minimum allocation.
    #  25% empirically seems to work
    size_range: 4

  # How long to wait before reaping lab container (in seconds)
  cull_timeout: 43200
  # Culling policy: "age" or "idle", colon, "local" or "remote"
  #  locality is relative to lab container; "remote" asks the hub
  #  to shut it down, "local" kills the local lab process.
  cull_policy: 'age:remote'

  repos: 'https://github.com/lsst-sqre/notebook-demo'

  # Set this to turn on the Multus CNI, necessary for bridging to the
  #  physical network at the summit.

  enable_multus: ''

  # This is used in SAL environments.  The value "nocontrol" means no SAL.
  dds_domain: 'nocontrol'


proxy:
  max_http_header_size: 16384
  ingress:
    host: ''
    annotations: []

wf:
  image: 'lsstsqre/wfdispatcher:latest'
  api_addr: '0.0.0.0'

js9:
  image: 'ericmandel/js9server:latest'

routes:
  hub: '/nb'
  firefly: '/portal/app/'
  js9: '/js9'
  api: '/api'
  tap: '/api/tap'
  soda: '/api/soda'
  wf: '/wf'

  external:
    fileserver: ''
    firefly: ''
    js9: ''
    instance: ''
    api: ''
    soda: ''
    hub: ''
    wf: ''

prepuller:
  minute_to_run: 35
  uid: 769
  gid: 769

reaper:
  # You only need one reaper globally for a given Lab image
  enabled: False
  hour_to_run: 2
  minute_to_run: 23
  keep_experimentals: 10
  keep_dailies: 15
  keep_weekies: 78
  user: 'cwalken'

mountpoints: |
  [
    {
      "mountpoint": "/home",
      "mode": "rw",
      "fileserver-export": "/home",
      "fileserver-host": ""
    },
    {
      "mountpoint": "/datasets",
      "fileserver-export": "/datasets",
      "fileserver-host": ""
    },
    {
      "mountpoint": "/software",
      "fileserver-export": "/software",
      "fileserver-host": ""
    },
    {
      "mountpoint": "/project",
      "mode": "rw",
      "fileserver-export": "/project",
      "fileserver-host": ""
    },
    {
      "mountpoint": "/scratch",
      "mode": "rw",
      "fileserver-export": "/scratch",
      "fileserver-host": ""
    }
  ]

resourcemap: |
  [
    { "disabled": true,
      "user": "Username for user with custom resources",
      "group": "Groupname for group with custom resources",
      "resources": {
        "size_index": "integer representing which size container is default: 0 is smallest",
        "mem_quota": "integer, namespace quota size in MB",
        "cpu_quota": "integer, namespace quota CPU limit"
      }
    }
  ]

jupyterhub_config: |
  '''Runtime configuration for JupyterHub in the LSST environment.
  '''

  import logging
  from eliot.stdlib import EliotHandler
  from jupyterhubutils import LSSTConfig
  from jupyterhubutils.authenticator import LSSTJWTAuthenticator
  from jupyterhubutils.scanrepo import prime_repo_cache
  from jupyterhubutils.spawner import LSSTSpawner
  from jupyterhubutils.utils import make_logger

  # get_config() only works in the Hub configuration environment
  c = get_config()

  lc = LSSTConfig()

  # Set up logging
  jhu_logger = make_logger(name='jupyterhubutils')
  if lc.debug:
      jhu_logger.setLevel(logging.DEBUG)
      jhu_logger.debug("Enabling 'jupyterhubutils' debug-level logging.")
      jhu_logger.warning("If there is no prior debug log something is wrong.")

  c.Application.log_format = lc.log_format
  c.Application.log_datefmt = lc.log_datefmt
  c.Application.log_level = lc.log_level
  c.Application.log = make_logger(name='JupyterHub')
  c.Application.log.handlers = [EliotHandler()]

  # Set authenticator and spawner classes
  c.JupyterHub.spawner_class = LSSTSpawner
  c.JupyterHub.authenticator_class = LSSTJWTAuthenticator

  # Prime the repo cache
  prime_repo_cache(lc)

  # Don't try to cleanup servers on exit - since in general for k8s, we want
  # the hub to be able to restart without losing user containers
  c.JupyterHub.cleanup_servers = False

  # Set Session DB URL if we have one
  db_url = lc.session_db_url
  if db_url:
      c.JupyterHub.db_url = db_url
  # Allow style overrides
  c.JupyterHub.template_paths = ["/opt/lsst/software/jupyterhub/templates/"]

  # Set Hub networking/routing parameters
  hub_route = lc.hub_route
  if hub_route != '/':
      c.JupyterHub.base_url = lc.hub_route

  # Set the Hub URLs
  c.JupyterHub.bind_url = lc.bind_url
  c.JupyterHub.hub_bind_url = lc.hub_bind_url
  c.JupyterHub.hub_connect_url = lc.hub_connect_url

  # External proxy
  c.ConfigurableHTTPProxy.should_start = False
  c.ConfigurableHTTPProxy.api_url = lc.proxy_api_url

base_passwd_file: |
  root:x:0:0:root:/root:/bin/bash
  bin:x:1:1:bin:/bin:/sbin/nologin
  daemon:x:2:2:daemon:/sbin:/sbin/nologin
  adm:x:3:4:adm:/var/adm:/sbin/nologin
  lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin
  sync:x:5:0:sync:/sbin:/bin/sync
  shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown
  halt:x:7:0:halt:/sbin:/sbin/halt
  mail:x:8:12:mail:/var/spool/mail:/sbin/nologin
  operator:x:11:0:operator:/root:/sbin/nologin
  games:x:12:100:games:/usr/games:/sbin/nologin
  ftp:x:14:50:FTP User:/var/ftp:/sbin/nologin
  nobody:x:99:99:Nobody:/:/sbin/nologin
  systemd-network:x:192:192:systemd Network Management:/:/sbin/nologin
  dbus:x:81:81:System message bus:/:/sbin/nologin
  lsst_lcl:x:1000:1000::/home/lsst_lcl:/bin/bash
  tss:x:59:59:Account used by the trousers package to sandbox the tcsd daemon:/dev/null:/sbin/nologin

base_group_file: |
  root:x:0:
  bin:x:1:
  daemon:x:2:
  sys:x:3:
  adm:x:4:
  tty:x:5:
  disk:x:6:
  lp:x:7:
  mem:x:8:
  kmem:x:9:
  wheel:x:10:
  cdrom:x:11:
  mail:x:12:
  man:x:15:
  dialout:x:18:
  floppy:x:19:
  games:x:20:
  tape:x:33:
  video:x:39:
  ftp:x:50:
  lock:x:54:
  audio:x:63:
  nobody:x:99:
  users:x:100:
  utmp:x:22:
  utempter:x:35:
  input:x:999:
  systemd-journal:x:190:
  systemd-network:x:192:
  dbus:x:81:
  ssh_keys:x:998:
  lsst_lcl:x:1000:
  tss:x:59:
  cgred:x:997:
  screen:x:84:
